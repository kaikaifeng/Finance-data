
\\Installing Spark 2.1.1
\\桌面上的.o之类的是64位Hadoop native lib，暂时先不要动，弄好了会删掉
\\在../fengkai里下了一份Tencent/angel，不知道好不好用。。
\\/home/hadoop/source/hadoop/etc/hadoop/masters 内容从hadoop2改为hadoop1，因为从其他配置看，hadoop1是master结点
\\/home/hadoop/source/hadoop/etc/hadoop/yarn-site.xml 中yarn.resourcemanager.address的值改为192.168.111.1:8032（从192.168.111.1:8040）
\\现在，运行hadoop程序时，貌似不会有org.apache.hadoop.ipc.RpcNoSuchProtocolException: Unknown protocol: org.apache.hadoop.yarn.api.ApplicationClientProtocolPB异常
测试使用的是hadoop自带示例，分别是：
hadoop jar /home/fengkai/hadoop-2.4.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.0.jar wordcount /input /outputTest
hadoop jar /home/fengkai/hadoop-2.4.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.4.0.jar pi 100 10000
例子是重新下载的。。原来并没有。。
\\算pi的那个，有时不能成功运行结束，可能是时钟同步的问题。。
查明是内存不足导致的，修改了内存分配后可以正常运行了，但是重现时没有成功，这次以及之后的尝试都卡死在UNASSIGNED状态

\\修复了原来hadoop4不能免密钥登陆的问题
\\服务器上原本就有spark 1.4.1，但是好像是单机版的。。
\\手动kill了原先已经不受控制的dataNode，NameNode（因为namespaceID和clusterID的综合错误）。删除了原先的tmp目录，hdfs目录，重新格式化了hdfs，现在应该可以正常运行了
\\各位最好自己尝试一下Hadoop。。
在使用时，最好不要用过时的start-all.sh和stop-all.sh，应使用start-dfs.sh和start-yarn.sh

\\mongodb的配置情况：hadoop3正常，hadoop2有，但是不能使用，hadoop1、hadoop4、hadoop5没有
\\在hadoop3、hadoop4、hadoop5上完成了zookeeper配置，运行；取代了之前存在的不知道是否正常的Hbase下zookeeper，现在是独立运行的zookeeper
端口号分别改为了2182、2887、3887，已解决端口占用问题

\\解决了Spark和hdfs关于namenode的端口号不一致的问题，现在统一使用8020端口
\\现在在yarn上的Spark还不能正常运行，貌似是因为一旦出现了网络连接错误，就会关掉整个任务，Hadoop也会遇到（可能）大量网络连接错误，但是会不断尝试
\\使用集群上的Spark前，在hadoop1上到Spark目录下的sbin目录中运行start-all.sh，使用stop-all.sh终止Spark服务

\\问题似乎解决了；问题应该是因为Spark找不到yarn配置文件导致的(以及原先缺少spark-defaults.conf文件)
\\尝试时可以使用spark-submit --jars /home/hadoop/source/spark-1.4.1-bin-hadoop2.4/lib/spark-assembly-1.4.1-hadoop2.4.0.jar --class org.apache.spark.examples.SparkPi --master yarn-client /home/hadoop/source/spark-1.4.1-bin-hadoop2.4/lib/spark-examples*.jar 10	10可以用其他数值替换
\\如果想在集群上使用shell，启动时使用spark-shell --master yarn，启动的时间有点长，需要等待一会儿。。
\\我在考虑是否需要出一个配置说明；还有，看来是必须学习一下scala

\\spark-shell --master yarn-client和spark-shell --master yarn没有不同，但是spark-shell --master yarn-cluster没有意义:Cluster deploy mode is not applicable to Spark shells.

\\降低了spark shell的日志级别到WARN（从INFO），如需修改，修改conf/log4j.properties中的log4j.rootCategory
\\刚刚发现spark-env.sh中HADOOP_HOME和HADOOP_CONF_DIR的路径不正确，修改到了正确路径（/home/hadoop/source下路径）

\\在hadoop1、2、3、4、5上都安装了maven，版本为3.5.0
\\优化了配置，具体为：
yarn-site.xml:
yarn.nodemanager.resource.cpu-vcores 替代 mapred.tasktracker.map.tasks.maximum
mapred-site.xml:
mapreduce.map.memory.mb 4096 => 2048
mapreduce.map.java.opts -Xmx6g => -Xmx1536m
mapreduce.reduce.java.opts -Xmx6g => -Xmx3072m
删除mapred.child.java.opts
spark-default.conf:
spark.executor.instances 15（尝试了15、50、200）应当可以通过减小内存分配提高executor数量，提高效率，目前50、200设置会引起进程的大量崩溃，这里的主要问题是各台机器都不能保证留给咱们确定大小的内存

\\奇怪的性能下降，需要监控工具

\\Dell R910不支持windows server2016

\\spark executor正常运行的数量目前最多达到20（通常达不到），瓶颈应是内存总量不足
\\sql server2012中可以使用bcp导出数据，基本命令为：
EXEC [数据库名称]..xp_cmdshell 'bcp [数据库名称].dbo.[表名] out F:\test\1.csv -c -T -S [服务器名称] -U [用户名称（管理员）]'
具体见服务器

\\选择了一种折中的方法，用其他语言程序生成需要的SQL脚本

\\服务器上直接插入硬盘是不能被识别的，必须配置RAID
\\缺少部分SZSE300的数据

\\为了运行时的稳定，将spark executor的数目减少到15
\\提供了构建scala jar包的“最简”（没有添加其他依赖）maven配置文件code/scala_sample/pom.xml
\\使用maven的基本方式是在pom.xml所在目录下运行指令mvn clean scala:compile package；依次完成清理、scala编译、打包；需要注意的是源程序目录结构需要满足src/main/scala
\\打包好的jar包可以使用spark-submit提交运行，提供的例子为：
spark-submit --master yarn-client --class com.buaa.financedata.sample.scala.Count ./target/finance-data-sample-0.0.1.jar
在完成编译、打包的目录下使用即可
\\spark-submit的性能暂时没有spark-shell好，可能有未发现的问题

\\java程序的基本打包命令是mvn clean compile package，其他与scala基本相同
